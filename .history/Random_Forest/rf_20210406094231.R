if (!require(tree))
  install.packages('tree')
library(tree)

if (!require(randomForest))
  install.packages("randomForest")
library(randomForest)

if (!require(randomForestExplainer))
  install.packages("randomForestExplainer")
library(randomForestExplainer)

if (!require(foreach))
  install.packages("foreach")
library(foreach)

if (!require(doFuture))
  install.packages("doFuture")
library(doFuture)

if (!require(progress))
  install.packages("progress")
library(progress)

if (!require(progressr))
  install.packages("progressr")
library(progressr)

data <-
  read.csv('data.csv',
           na.strings = '?',
           stringsAsFactors = T)
data <- subset(data, select = -c(X))

# data$Result[data$Result == 1] <- 'Malware'
# data$Result[data$Result == 0] <- 'Safe'
data$Result <- as.factor(data$Result)

ncol(data)
nrow(data)

str(data$Result)

set.seed(1)

# split sample and test
#train <- sample(1:nrow(data), nrow(data) * 0.8)
train <- (1:(nrow(data)-500))
test <- data[-train, ]


##### Decision Tree #####

# plant a tree
data.tree <- tree(Result ~ ., data = data)

summary(data.tree)
#+ fig.width=11, fig.height=8
plot(data.tree)
text(data.tree, pretty = 0)


data.tree <- tree(Result ~ ., data = data, subset = train)
data.tree.pred = predict(data.tree, test, type = "class")

table(data.tree.pred, test$Result)
mean(data.tree.pred == test$Result)

# cross validating different trees
cv.data <- cv.tree(data.tree, FUN = prune.misclass)
names(cv.data)
#+ fig.width=11, fig.height=8
plot(cv.data)
cv.data

# get the best tree
prune.data <-
  prune.misclass(data.tree, best = cv.data$size[which.min(cv.data$dev)])
#+ fig.width=11, fig.height=8
plot(prune.data)
text(prune.data, pretty = 0)

prune.data.pred <- predict(prune.data, test, type = "class")
table(prune.data.pred, test$Result)
mean(prune.data.pred == test$Result)


##### Random Forest #####

numTree <- 5000

# baseline forest
data.forest <- randomForest(
  Result ~ .,
  data = data,
  subset = train,
  ntree = numTree,
  importance = T,
  localImp = T
)
data.forest
plot(data.forest)

# testing hyper peramiter: mtry
data.forest <- randomForest(
  Result ~ .,
  data = data,
  subset = train,
  ntree = numTree,
  mtry = ncol(data) - 1,
  importance = T,
  localImp = T
)
data.forest
#+ fig.width=11, fig.height=8
plot(data.forest)

importance(data.forest)
varImpPlot(data.forest)

data.forest.pred <- predict(data.forest, test, typr = "class")
table(data.forest.pred, test$Result)
mean(data.forest.pred == test$Result)

pb <- progress_bar$new(format = ":elapsedfull [:bar] :current/:total (:percent)", total = (ncol(data) - 1))

mtry.list <- c()
data.forest.final <- NULL
max <- 0
for (i in 1:(ncol(data) - 1)) {
  data.forest.dummy <- randomForest(
    Result ~ .,
    data = data,
    subset = train,
    ntree = numTree,
    mtry = i,
    importance = T,
    localImp = T
  )
  val <- predict(data.forest.dummy, test, typr = "class")
  score <- mean(val == test$Result)
  if (score >= max) {
    data.forest.final <- data.forest.dummy
    max <- score
  }
  mtry.list[i] <- score
  pb$tick()
}


# registerDoFuture()
# plan(multisession, workers = 7)
# 
# ptm <- proc.time()
# 
# mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
#   data.forest.dummy <- randomForest(
#     Result ~ .,
#     data = data,
#     subset = train,
#     ntree = numTree,
#     mtry = i,
#     importance = T,
#     localImp = T
#   )
#   
#   val <- predict(data.forest.dummy, test, typr = "class")
#   score <- mean(val == test$Result)
#   print("%s mtry: %s -- score: %s", (proc.time() - ptm), i, score)
#   data.frame(mtry = i, result = score)
# }
# 
# proc.time() - ptm

mtry.list

#+ fig.width=11, fig.height=8
plot(mtry.list)

data.forest.final

#+ fig.width=11, fig.height=8
plot(data.forest.final)

importance(data.forest.final)
#+ fig.width=11, fig.height=8
varImpPlot(data.forest.final)

data.forest.final.pred <-
  predict(data.forest.final, test, typr = "class")
table(data.forest.final.pred, test$Result)
mean(data.forest.final.pred == test$Result)

explain_forest(data.forest.final, interactions = TRUE, data = data)
# explain_forest(data.forest.final, data = data)
