#+ fig.width=11, fig.height=8
varImpPlot(data.forest.final)
data.forest.final.pred <-
predict(data.forest.final, test, typr = "class")
table(data.forest.final.pred, test$Result)
mean(data.forest.final.pred == test$Result)
registerDoFuture()
plan(multiprocess)
pb <- txtProgressBar(max = (ncol(data) - 1), style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind, .options.snow = opts) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
score
}
close(pb)
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list)
data.forest.final
#+ fig.width=11, fig.height=8
plot(data.forest.final)
log.socket <- make.socket(port=4000)
Log <- function(text, ...) {
msg <- sprintf(paste0(as.character(Sys.time()), ": ", text, "\n"), ...)
cat(msg)
write.socket(log.socket, msg)
}
registerDoFuture()
plan(multiprocess)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
Log("Processing block %d of %d", i, (ncol(data) - 1))
score
}
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list)
data.forest.final
log.socket <- make.socket(port=8088)
Log <- function(text, ...) {
msg <- sprintf(paste0(as.character(Sys.time()), ": ", text, "\n"), ...)
cat(msg)
write.socket(log.socket, msg)
}
registerDoFuture()
plan(multiprocess)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
Log("Processing block %d of %d", i, (ncol(data) - 1))
score
}
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list)
registerDoFuture()
plan(multiprocess)
pb <- txtProgressBar(min = 1, max = (ncol(data) - 1), style = 3)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
setTxtProgressBar(pb, i)
c(i,score)
}
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list)
registerDoFuture()
plan(multiprocess)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(c(i,score))
c(i,score)
}
mtry.list
pb <- progress_bar$new(format = ":elapsedfull [:bar] :current/:total (:percent)", total = (ncol(data) - 1))
#
# mtry.list <- c()
# data.forest.final <- NULL
# max <- 0
# for (i in 1:(ncol(data) - 1)) {
#   data.forest.dummy <- randomForest(
#     Result ~ .,
#     data = data,
#     subset = train,
#     ntree = numTree,
#     mtry = i,
#     importance = T,
#     localImp = T
#   )
#   val <- predict(data.forest.dummy, test, typr = "class")
#   score <- mean(val == test$Result)
#   if (score >= max) {
#     data.forest.final <- data.forest.dummy
#     max <- score
#   }
#   mtry.list[i] <- score
#   pb$tick()
# }
#
registerDoFuture()
plan(multiprocess)
progress <- function(n){
pb$tick()
}
opts <- list(progress = progress)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = cbind, .options.snow = opts) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(c(i,score))
c(i,score)
}
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list)
registerDoFuture()
plan(multicore)
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(data.frame(id = i,result = score))
data.frame(id = i,result = score, model = data.forest.dummy)
}
mtry.list
registerDoFuture()
plan(multicore)
ptm <- proc.time()
# mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
mtry.list <- foreach(i = 1:16, .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(data.frame(id = i,result = score))
data.frame(id = i,result = score, model = data.forest.dummy)
}
proc.time() - ptm
mtry.list
if (!require(tree))
install.packages('tree')
library(tree)
if (!require(randomForest))
install.packages("randomForest")
library(randomForest)
if (!require(randomForestExplainer))
install.packages("randomForestExplainer")
library(randomForestExplainer)
if (!require(foreach))
install.packages("foreach")
library(foreach)
if (!require(doFuture))
install.packages("doFuture")
library(doFuture)
if (!require(progress))
install.packages("progress")
library(progress)
if (!require(progressr))
install.packages("progressr")
library(progressr)
data <-
read.csv('data.csv',
na.strings = '?',
stringsAsFactors = T)
data <- subset(data, select = -c(X))
# data$Result[data$Result == 1] <- 'Malware'
# data$Result[data$Result == 0] <- 'Safe'
data$Result <- as.factor(data$Result)
ncol(data)
nrow(data)
str(data$Result)
set.seed(1)
# split sample and test
train <- sample(1:nrow(data), nrow(data) * 0.8)
test <- data[-train,]
##### Decision Tree #####
# plant a tree
data.tree <- tree(Result ~ ., data = data)
summary(data.tree)
#+ fig.width=11, fig.height=8
plot(data.tree)
text(data.tree, pretty = 0)
data.tree <- tree(Result ~ ., data = data, subset = train)
data.tree.pred = predict(data.tree, test, type = "class")
table(data.tree.pred, test$Result)
mean(data.tree.pred == test$Result)
# cross validating different trees
cv.data <- cv.tree(data.tree, FUN = prune.misclass)
names(cv.data)
#+ fig.width=11, fig.height=8
plot(cv.data)
cv.data
# get the best tree
prune.data <-
prune.misclass(data.tree, best = cv.data$size[which.min(cv.data$dev)])
#+ fig.width=11, fig.height=8
plot(prune.data)
text(prune.data, pretty = 0)
prune.data.pred <- predict(prune.data, test, type = "class")
table(prune.data.pred, test$Result)
mean(prune.data.pred == test$Result)
##### Random Forest #####
numTree <- 5000
# baseline forest
data.forest <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
importance = T,
localImp = T
)
data.forest
plot(data.forest)
# testing hyper peramiter: mtry
data.forest <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = ncol(data) - 1,
importance = T,
localImp = T
)
data.forest
#+ fig.width=11, fig.height=8
plot(data.forest)
importance(data.forest)
varImpPlot(data.forest)
data.forest.pred <- predict(data.forest, test, typr = "class")
table(data.forest.pred, test$Result)
mean(data.forest.pred == test$Result)
# pb <- progress_bar$new(format = ":elapsedfull [:bar] :current/:total (:percent)", total = (ncol(data) - 1))
#
# mtry.list <- c()
# data.forest.final <- NULL
# max <- 0
# for (i in 1:(ncol(data) - 1)) {
#   data.forest.dummy <- randomForest(
#     Result ~ .,
#     data = data,
#     subset = train,
#     ntree = numTree,
#     mtry = i,
#     importance = T,
#     localImp = T
#   )
#   val <- predict(data.forest.dummy, test, typr = "class")
#   score <- mean(val == test$Result)
#   if (score >= max) {
#     data.forest.final <- data.forest.dummy
#     max <- score
#   }
#   mtry.list[i] <- score
#   pb$tick()
# }
#
registerDoFuture()
plan(multicore)
ptm <- proc.time()
# mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
mtry.list <- foreach(i = 1:32, .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(data.frame(id = i,result = score))
data.frame(id = i,result = score, model = data.forest.dummy)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(multiprocess)
ptm <- proc.time()
# mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
mtry.list <- foreach(i = 1:32, .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print(data.frame(id = i,result = score))
data.frame(id = i,result = score, model = data.forest.dummy)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(multiprocess)
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
cat("\r",paste(i,score))
data.frame(mtry = i,result = score)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(MultisessionFuture)
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
cat("\r"," mtry: ", i, " -- score ", score, sep = "")
data.frame(mtry = i, result = score)
}
proc.time() - ptm
mtry.list
#+ fig.width=11, fig.height=8
plot(mtry.list$result)
data.forest.final <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = mtry.list[[which.max(mtry.list$result)]][mtry],
importance = T,
localImp = T
)
#+ fig.width=11, fig.height=8
plot(data.forest.final)
importance(data.forest.final)
#+ fig.width=11, fig.height=8
varImpPlot(data.forest.final)
data.forest.final.pred <-
predict(data.forest.final, test, typr = "class")
table(data.forest.final.pred, test$Result)
mean(data.forest.final.pred == test$Result)
registerDoFuture()
plan(MultisessionFuture)
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
cat("\r"," mtry: ", i, " -- score ", score, sep = "")
data.frame(mtry = i, result = score)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(multisession())
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
cat("\r"," mtry: ", i, " -- score ", score, sep = "")
data.frame(mtry = i, result = score)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(multisession)
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
cat("\r"," mtry: ", i, " -- score ", score, sep = "")
data.frame(mtry = i, result = score)
}
proc.time() - ptm
mtry.list
registerDoFuture()
plan(multisession)
ptm <- proc.time()
mtry.list <- foreach(i = 1:(ncol(data) - 1), .combine = rbind) %dopar% {
data.forest.dummy <- randomForest(
Result ~ .,
data = data,
subset = train,
ntree = numTree,
mtry = i,
importance = T,
localImp = T
)
val <- predict(data.forest.dummy, test, typr = "class")
score <- mean(val == test$Result)
print("%s mtry: %s -- score: %s", (proc.time() - ptm), i, score)
data.frame(mtry = i, result = score)
}
proc.time() - ptm
mtry.list
